# Linear-Regression-using-Gradient-Descent
#100daysofMLcode

Day 2: I spent time understanding how to perform linear regression using gradient descent.

# Key Concepts:
1) Gradient Descent: Optimization of a function in order to find its minimum value
2) Hyperparameters: Parameters for fine tuning the model
3) Learning Rate: A hyperparameter which defines how quickly the weights are adjusted
4) Number of Iterations: A hyperparameter which defines how many times a model needs to learn before converging
5) Partial Derivative: Derivative of a function based on two or more variables with respect to one variable (all other variables are treated as constants in this case)

# Credits:
Credit to Siraj Raval for explaining the concept of gradient descent very well.
